{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XL5MEkLcfRD2",
        "9Xis6ldDfTs6"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#AutoEncoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbiqOK7dLGG"
      },
      "source": [
        "##Downloading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5MEkLcfRD2"
      },
      "source": [
        "###ML-100K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjOPzue7FCXJ",
        "outputId": "c90e7ec6-6c2d-4afe-a84c-77552a818079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "!unzip ml-100k.zip\n",
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 08:23:49--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip.1’\n",
            "\n",
            "ml-100k.zip.1       100%[===================>]   4.70M  11.2MB/s    in 0.4s    \n",
            "\n",
            "2023-10-16 08:23:49 (11.2 MB/s) - ‘ml-100k.zip.1’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: ml-100k  ml-100k.zip  ml-100k.zip.1  ml-1m  ml-1m.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xis6ldDfTs6"
      },
      "source": [
        "###ML-1M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOly1yfAfTjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4267d61f-cea9-4300-8a77-23e76db87e5a"
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "!unzip ml-1m.zip\n",
        "!ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 08:24:44--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip.1’\n",
            "\n",
            "ml-1m.zip.1         100%[===================>]   5.64M  13.4MB/s    in 0.4s    \n",
            "\n",
            "2023-10-16 08:24:44 (13.4 MB/s) - ‘ml-1m.zip.1’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "replace ml-1m/movies.dat? [y]es, [n]o, [A]ll, [N]one, [r]ename: ml-100k  ml-100k.zip  ml-100k.zip.1  ml-1m  ml-1m.zip  ml-1m.zip.1  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOBJ8UCXdY0g"
      },
      "source": [
        "##Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LvGeU1CeCtg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM04FyMudkoK"
      },
      "source": [
        "## Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJw2p3-Cewo4"
      },
      "source": [
        "# We won't be using this dataset.\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTIbE2tkdkwP"
      },
      "source": [
        "## Preparing the training set and the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2usLKJBEgPE2"
      },
      "source": [
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCf8HjSydk4s"
      },
      "source": [
        "## Getting the number of users and movies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPaGZqdniC5m"
      },
      "source": [
        "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users, nb_movies"
      ],
      "metadata": {
        "id": "GeYZ7O_UELyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021dd2a0-57bb-49c5-e760-de0dbcc54ffc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 1682)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-w4-hVidlAm"
      },
      "source": [
        "## Converting the data into an array with users in lines and movies in columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wASs2YFiDaa"
      },
      "source": [
        "def convert(data):\n",
        "  new_data = []\n",
        "  # 1 user : n movie ratings 로 구조 변경\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
        "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
        "    # 평가하지 않은 영화 = 0\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "oRzej47SEci7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMmhuUpldlHo"
      },
      "source": [
        "## Converting the data into Torch tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "bjvHAXkyFXOl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kkL8NkkdlZj"
      },
      "source": [
        "## Creating the architecture of the Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn 상속\n",
        "class SAE(nn.Module):\n",
        "\n",
        "  def __init__(self, ):\n",
        "    super(SAE,self).__init__()\n",
        "\n",
        "    # 층 생성\n",
        "    self.fc1 = nn.Linear(nb_movies, 32) # 입력 노드 수, 첫번째 은닉층 노드 수(인코딩)\n",
        "    self.fc2 = nn.Linear(32, 16)        # 첫번째 은닉층 노드 수, 두번째 은닉층 노드 수(인코딩)\n",
        "    self.fc3 = nn.Linear(16, 32)        # 두번째 은닉층 노드 수, 세번째 은닉층 노드 수(디코딩)\n",
        "    self.fc4 = nn.Linear(32, nb_movies) # 두번째 은닉층 노드 수, 출력 노드 수(디코딩)\n",
        "\n",
        "    # 활성화 함수\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  # 순전파\n",
        "  def forward(self, x): # x : 입력벡터\n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.activation(self.fc2(x))\n",
        "    x = self.activation(self.fc3(x))\n",
        "    x = self.fc4(x)   # 출력층에는 활성화함수X\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "R1y3tkjGGEl5"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sae = SAE()"
      ],
      "metadata": {
        "id": "jQWgdC9tOciw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "metadata": {
        "id": "YQy_9v36OipH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gy59alAdloL"
      },
      "source": [
        "## Training the SAE (Stacked Auto Encoder)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch 수 지정\n",
        "nb_epoch = 200\n",
        "\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "  # 오차 초기화\n",
        "  train_loss = 0\n",
        "  # 적어도 한 편 이상의 영화를 평가한 유저의 수\n",
        "  s = 0.\n",
        "\n",
        "  for id_user in range(nb_users):\n",
        "    # from torch.autograd import Variable\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0) # unsqueeze : 더미 차원 생성\n",
        "    # 수정 입력 벡터\n",
        "    target = input.clone()\n",
        "\n",
        "    # 메모리 최적화를 위해 적어도 한 편 이상의 영화를 평가한 유저만 사용\n",
        "    if torch.sum(target.data > 0) > 0 :\n",
        "      output = sae.forward(input)\n",
        "      target.require_grad = False # 미분 계산x\n",
        "      output[target == 0] = 0\n",
        "      # 오차 계산\n",
        "      loss = criterion(output, target)\n",
        "      # 오차의 평균( + 1e-10 : 분모가 0인 것을 피하기 위함)\n",
        "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "      loss.backward()\n",
        "      train_loss += np.sqrt(loss.data * mean_corrector)\n",
        "      s += 1.\n",
        "\n",
        "      # optimizer 생성\n",
        "      optimizer.step()\n",
        "\n",
        "  print('epoch : '+str(epoch)+'  loss : '+str(train_loss/s))"
      ],
      "metadata": {
        "id": "XVvhW5juGFGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a112ea60-9fe5-429a-ad85-ef229b216abc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1  loss : tensor(1.6008)\n",
            "epoch : 2  loss : tensor(1.0753)\n",
            "epoch : 3  loss : tensor(1.0507)\n",
            "epoch : 4  loss : tensor(1.0422)\n",
            "epoch : 5  loss : tensor(1.0384)\n",
            "epoch : 6  loss : tensor(1.0360)\n",
            "epoch : 7  loss : tensor(1.0349)\n",
            "epoch : 8  loss : tensor(1.0334)\n",
            "epoch : 9  loss : tensor(1.0335)\n",
            "epoch : 10  loss : tensor(1.0324)\n",
            "epoch : 11  loss : tensor(1.0322)\n",
            "epoch : 12  loss : tensor(1.0314)\n",
            "epoch : 13  loss : tensor(1.0315)\n",
            "epoch : 14  loss : tensor(1.0284)\n",
            "epoch : 15  loss : tensor(1.0273)\n",
            "epoch : 16  loss : tensor(1.0226)\n",
            "epoch : 17  loss : tensor(1.0238)\n",
            "epoch : 18  loss : tensor(1.0180)\n",
            "epoch : 19  loss : tensor(1.0211)\n",
            "epoch : 20  loss : tensor(1.0149)\n",
            "epoch : 21  loss : tensor(1.0165)\n",
            "epoch : 22  loss : tensor(1.0120)\n",
            "epoch : 23  loss : tensor(1.0121)\n",
            "epoch : 24  loss : tensor(1.0088)\n",
            "epoch : 25  loss : tensor(1.0108)\n",
            "epoch : 26  loss : tensor(1.0058)\n",
            "epoch : 27  loss : tensor(1.0073)\n",
            "epoch : 28  loss : tensor(1.0027)\n",
            "epoch : 29  loss : tensor(1.0031)\n",
            "epoch : 30  loss : tensor(1.0005)\n",
            "epoch : 31  loss : tensor(1.0056)\n",
            "epoch : 32  loss : tensor(0.9976)\n",
            "epoch : 33  loss : tensor(0.9973)\n",
            "epoch : 34  loss : tensor(0.9948)\n",
            "epoch : 35  loss : tensor(0.9968)\n",
            "epoch : 36  loss : tensor(0.9917)\n",
            "epoch : 37  loss : tensor(0.9914)\n",
            "epoch : 38  loss : tensor(0.9860)\n",
            "epoch : 39  loss : tensor(0.9883)\n",
            "epoch : 40  loss : tensor(0.9810)\n",
            "epoch : 41  loss : tensor(0.9805)\n",
            "epoch : 42  loss : tensor(0.9768)\n",
            "epoch : 43  loss : tensor(0.9827)\n",
            "epoch : 44  loss : tensor(0.9771)\n",
            "epoch : 45  loss : tensor(0.9782)\n",
            "epoch : 46  loss : tensor(0.9756)\n",
            "epoch : 47  loss : tensor(0.9752)\n",
            "epoch : 48  loss : tensor(0.9714)\n",
            "epoch : 49  loss : tensor(0.9708)\n",
            "epoch : 50  loss : tensor(0.9662)\n",
            "epoch : 51  loss : tensor(0.9681)\n",
            "epoch : 52  loss : tensor(0.9647)\n",
            "epoch : 53  loss : tensor(0.9634)\n",
            "epoch : 54  loss : tensor(0.9600)\n",
            "epoch : 55  loss : tensor(0.9608)\n",
            "epoch : 56  loss : tensor(0.9592)\n",
            "epoch : 57  loss : tensor(0.9599)\n",
            "epoch : 58  loss : tensor(0.9588)\n",
            "epoch : 59  loss : tensor(0.9569)\n",
            "epoch : 60  loss : tensor(0.9553)\n",
            "epoch : 61  loss : tensor(0.9551)\n",
            "epoch : 62  loss : tensor(0.9525)\n",
            "epoch : 63  loss : tensor(0.9527)\n",
            "epoch : 64  loss : tensor(0.9504)\n",
            "epoch : 65  loss : tensor(0.9512)\n",
            "epoch : 66  loss : tensor(0.9497)\n",
            "epoch : 67  loss : tensor(0.9498)\n",
            "epoch : 68  loss : tensor(0.9486)\n",
            "epoch : 69  loss : tensor(0.9482)\n",
            "epoch : 70  loss : tensor(0.9470)\n",
            "epoch : 71  loss : tensor(0.9470)\n",
            "epoch : 72  loss : tensor(0.9457)\n",
            "epoch : 73  loss : tensor(0.9457)\n",
            "epoch : 74  loss : tensor(0.9443)\n",
            "epoch : 75  loss : tensor(0.9441)\n",
            "epoch : 76  loss : tensor(0.9427)\n",
            "epoch : 77  loss : tensor(0.9432)\n",
            "epoch : 78  loss : tensor(0.9437)\n",
            "epoch : 79  loss : tensor(0.9452)\n",
            "epoch : 80  loss : tensor(0.9409)\n",
            "epoch : 81  loss : tensor(0.9411)\n",
            "epoch : 82  loss : tensor(0.9395)\n",
            "epoch : 83  loss : tensor(0.9399)\n",
            "epoch : 84  loss : tensor(0.9387)\n",
            "epoch : 85  loss : tensor(0.9389)\n",
            "epoch : 86  loss : tensor(0.9384)\n",
            "epoch : 87  loss : tensor(0.9381)\n",
            "epoch : 88  loss : tensor(0.9369)\n",
            "epoch : 89  loss : tensor(0.9369)\n",
            "epoch : 90  loss : tensor(0.9359)\n",
            "epoch : 91  loss : tensor(0.9360)\n",
            "epoch : 92  loss : tensor(0.9354)\n",
            "epoch : 93  loss : tensor(0.9354)\n",
            "epoch : 94  loss : tensor(0.9344)\n",
            "epoch : 95  loss : tensor(0.9345)\n",
            "epoch : 96  loss : tensor(0.9337)\n",
            "epoch : 97  loss : tensor(0.9336)\n",
            "epoch : 98  loss : tensor(0.9329)\n",
            "epoch : 99  loss : tensor(0.9330)\n",
            "epoch : 100  loss : tensor(0.9320)\n",
            "epoch : 101  loss : tensor(0.9321)\n",
            "epoch : 102  loss : tensor(0.9313)\n",
            "epoch : 103  loss : tensor(0.9316)\n",
            "epoch : 104  loss : tensor(0.9309)\n",
            "epoch : 105  loss : tensor(0.9308)\n",
            "epoch : 106  loss : tensor(0.9297)\n",
            "epoch : 107  loss : tensor(0.9303)\n",
            "epoch : 108  loss : tensor(0.9291)\n",
            "epoch : 109  loss : tensor(0.9294)\n",
            "epoch : 110  loss : tensor(0.9281)\n",
            "epoch : 111  loss : tensor(0.9287)\n",
            "epoch : 112  loss : tensor(0.9273)\n",
            "epoch : 113  loss : tensor(0.9282)\n",
            "epoch : 114  loss : tensor(0.9271)\n",
            "epoch : 115  loss : tensor(0.9275)\n",
            "epoch : 116  loss : tensor(0.9263)\n",
            "epoch : 117  loss : tensor(0.9269)\n",
            "epoch : 118  loss : tensor(0.9257)\n",
            "epoch : 119  loss : tensor(0.9263)\n",
            "epoch : 120  loss : tensor(0.9248)\n",
            "epoch : 121  loss : tensor(0.9258)\n",
            "epoch : 122  loss : tensor(0.9244)\n",
            "epoch : 123  loss : tensor(0.9249)\n",
            "epoch : 124  loss : tensor(0.9240)\n",
            "epoch : 125  loss : tensor(0.9246)\n",
            "epoch : 126  loss : tensor(0.9235)\n",
            "epoch : 127  loss : tensor(0.9242)\n",
            "epoch : 128  loss : tensor(0.9233)\n",
            "epoch : 129  loss : tensor(0.9239)\n",
            "epoch : 130  loss : tensor(0.9226)\n",
            "epoch : 131  loss : tensor(0.9233)\n",
            "epoch : 132  loss : tensor(0.9223)\n",
            "epoch : 133  loss : tensor(0.9229)\n",
            "epoch : 134  loss : tensor(0.9216)\n",
            "epoch : 135  loss : tensor(0.9221)\n",
            "epoch : 136  loss : tensor(0.9214)\n",
            "epoch : 137  loss : tensor(0.9219)\n",
            "epoch : 138  loss : tensor(0.9210)\n",
            "epoch : 139  loss : tensor(0.9215)\n",
            "epoch : 140  loss : tensor(0.9208)\n",
            "epoch : 141  loss : tensor(0.9209)\n",
            "epoch : 142  loss : tensor(0.9200)\n",
            "epoch : 143  loss : tensor(0.9205)\n",
            "epoch : 144  loss : tensor(0.9197)\n",
            "epoch : 145  loss : tensor(0.9199)\n",
            "epoch : 146  loss : tensor(0.9190)\n",
            "epoch : 147  loss : tensor(0.9194)\n",
            "epoch : 148  loss : tensor(0.9188)\n",
            "epoch : 149  loss : tensor(0.9195)\n",
            "epoch : 150  loss : tensor(0.9187)\n",
            "epoch : 151  loss : tensor(0.9189)\n",
            "epoch : 152  loss : tensor(0.9181)\n",
            "epoch : 153  loss : tensor(0.9185)\n",
            "epoch : 154  loss : tensor(0.9178)\n",
            "epoch : 155  loss : tensor(0.9180)\n",
            "epoch : 156  loss : tensor(0.9173)\n",
            "epoch : 157  loss : tensor(0.9175)\n",
            "epoch : 158  loss : tensor(0.9172)\n",
            "epoch : 159  loss : tensor(0.9171)\n",
            "epoch : 160  loss : tensor(0.9167)\n",
            "epoch : 161  loss : tensor(0.9168)\n",
            "epoch : 162  loss : tensor(0.9166)\n",
            "epoch : 163  loss : tensor(0.9166)\n",
            "epoch : 164  loss : tensor(0.9161)\n",
            "epoch : 165  loss : tensor(0.9161)\n",
            "epoch : 166  loss : tensor(0.9158)\n",
            "epoch : 167  loss : tensor(0.9157)\n",
            "epoch : 168  loss : tensor(0.9154)\n",
            "epoch : 169  loss : tensor(0.9153)\n",
            "epoch : 170  loss : tensor(0.9149)\n",
            "epoch : 171  loss : tensor(0.9149)\n",
            "epoch : 172  loss : tensor(0.9144)\n",
            "epoch : 173  loss : tensor(0.9144)\n",
            "epoch : 174  loss : tensor(0.9142)\n",
            "epoch : 175  loss : tensor(0.9139)\n",
            "epoch : 176  loss : tensor(0.9138)\n",
            "epoch : 177  loss : tensor(0.9134)\n",
            "epoch : 178  loss : tensor(0.9134)\n",
            "epoch : 179  loss : tensor(0.9131)\n",
            "epoch : 180  loss : tensor(0.9129)\n",
            "epoch : 181  loss : tensor(0.9125)\n",
            "epoch : 182  loss : tensor(0.9121)\n",
            "epoch : 183  loss : tensor(0.9120)\n",
            "epoch : 184  loss : tensor(0.9116)\n",
            "epoch : 185  loss : tensor(0.9113)\n",
            "epoch : 186  loss : tensor(0.9110)\n",
            "epoch : 187  loss : tensor(0.9106)\n",
            "epoch : 188  loss : tensor(0.9100)\n",
            "epoch : 189  loss : tensor(0.9098)\n",
            "epoch : 190  loss : tensor(0.9095)\n",
            "epoch : 191  loss : tensor(0.9090)\n",
            "epoch : 192  loss : tensor(0.9086)\n",
            "epoch : 193  loss : tensor(0.9081)\n",
            "epoch : 194  loss : tensor(0.9078)\n",
            "epoch : 195  loss : tensor(0.9072)\n",
            "epoch : 196  loss : tensor(0.9070)\n",
            "epoch : 197  loss : tensor(0.9065)\n",
            "epoch : 198  loss : tensor(0.9059)\n",
            "epoch : 199  loss : tensor(0.9054)\n",
            "epoch : 200  loss : tensor(0.9046)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20->10->20 | epoch : 200  loss : tensor(0.9065)\n",
        "# 32->16->32 | epoch : 200  loss : tensor(0.9046)"
      ],
      "metadata": {
        "id": "sLdtRYuBdq21"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bak5uc8gd-gX"
      },
      "source": [
        "## Testing the SAE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "\n",
        "for id_user in range(nb_users):\n",
        "  input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "  target = Variable(test_set[id_user])\n",
        "\n",
        "  if torch.sum(target.data > 0) > 0 :\n",
        "    output = sae(input)[0]\n",
        "    target.require_grad = False\n",
        "    output[target == 0] = 0\n",
        "    loss = criterion(output, target)\n",
        "    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "    test_loss += np.sqrt(loss.data * mean_corrector)\n",
        "    s += 1.\n",
        "\n",
        "\n",
        "print('loss : '+str(test_loss/s))"
      ],
      "metadata": {
        "id": "Sa3PEQAbGFc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17385e24-5778-4a1f-ed60-348f10671258"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : tensor(0.9502)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20->10->20 | loss : tensor(0.9577)\n",
        "# 32->16->32 | loss : tensor(0.9502)"
      ],
      "metadata": {
        "id": "-vMp4W-Pj0pM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZc8UgUln8Xc"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}